{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline de Dados Telegram - Gastos Pessoais**\n",
        "\n",
        "## **1.Motivação do Projeto**\n",
        "\n",
        "Vivemos em um mundo onde dados são gerados a todo momento. Mas como transformar essas informações em insights valiosos?\n",
        "\n",
        "Imagine que você quer monitorar seus gastos automaticamente, sem precisar inserir manualmente cada transação em uma planilha.\n",
        "\n",
        "Foi com essa ideia que nasceu este projeto: um **pipeline de dados do Telegram**, onde um chatbot captura mensagens contendo despesas, armazena os dados, processa e os disponibiliza para análise.\n",
        "\n",
        "## **2. Contexto**\n",
        "\n",
        "### **Chatbots e a Geração de Dados**\n",
        "\n",
        "Os chatbots estão cada vez mais presentes no nosso dia a dia, facilitando interações e automatizando tarefas. O Telegram, por exemplo, permite a criação de bots que capturam mensagens enviadas pelos usuários e as disponibilizam via API.\n",
        "\n",
        "### **Dados Transacionais vs. Dados Analíticos**\n",
        "\n",
        "- **Dados transacionais**: Registram eventos individuais no dia a dia de uma empresa ou usuário (como uma compra).\n",
        "- **Dados analíticos**: São estruturados e processados para gerar insights e auxiliar na tomada de decisões.\n",
        "\n",
        "Nosso projeto parte de dados transacionais capturados no Telegram e os transforma em um conjunto de dados analíticos para análise de gastos pessoais.\n",
        "\n",
        "## **3. Arquitetura do Sistema**\n",
        "\n",
        "![diagrama pipeline_.jpg](https://github.com/davicarv/Portfolio/blob/main/Pipeline%20de%20Dados/Diagrama%20Pipeline.drawio.png?raw=true)\n"
      ],
      "metadata": {
        "id": "otCOle13UlzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **3.1. Sistema Transacional: Captura de Dados do Telegram**\n",
        "\n",
        "- Um bot no Telegram recebe mensagens estruturadas no formato:\n",
        "  ```\n",
        "  Descrição, Valor, Data, Categoria, Método de Pagamento, Banco\n",
        "  ```\n",
        "- Essas mensagens são coletadas usando a API do Telegram.\n",
        "\n",
        "### **3.2. Pipeline Analítico: Ingestão, ETL e Apresentação**\n",
        "\n",
        "**Ingestão:**\n",
        "\n",
        "Para capturar as mensagens enviadas ao bot do Telegram em tempo real, utilizamos um Webhook com O AWS API Gateway:\n",
        "\n",
        "- O Telegram envia automaticamente as mensagens recebidas pelo bot para uma URL definida (Webhook).\n",
        "\n",
        "- O Amazon API Gateway é responsável por expor a URL do Webhook de forma segura e escalável. Ele atua como um intermediário entre o Telegram e a AWS, permitindo o recebimento de mensagens em tempo real.\n",
        "- Quando o bot recebe uma nova mensagem, o Telegram envia automaticamente os dados para o Webhook configurado.\n",
        "- O API Gateway recebe essa solicitação e a encaminha para uma função AWS Lambda, que processa a requisição, extrai os dados da mensagem e os armazena no Amazon S3 no formato JSON. A função Lambda é a seguinte:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SOoxcC9bW9JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "import boto3\n",
        "\n",
        "def lambda_handler(event: dict, context: dict) -> dict:\n",
        "    '''\n",
        "    Recebe uma mensagem do Telegram via AWS API Gateway, verifica no\n",
        "    seu conteúdo se foi produzida em um determinado grupo e a escreve,\n",
        "    em seu formato original JSON, em um bucket do AWS S3.\n",
        "    '''\n",
        "\n",
        "    # Variáveis de ambiente\n",
        "    BUCKET = os.environ['BUCKET_NAME']\n",
        "    TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_GROUP_ID'])\n",
        "\n",
        "    # Variáveis lógicas (Data e hora)\n",
        "    tzinfo = timezone(offset=timedelta(hours=-3))  # Definindo o fuso horário\n",
        "    date = datetime.now(tzinfo).strftime('%Y-%m-%d')  # Data formatada\n",
        "    timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')  # Timestamp único\n",
        "\n",
        "    filename = f'{timestamp}.json'\n",
        "\n",
        "    # Cliente boto3 para S3\n",
        "    client = boto3.client('s3')\n",
        "\n",
        "    try:\n",
        "        # Carrega o corpo da requisição\n",
        "        message = json.loads(event[\"body\"])  # Carrega o conteúdo do evento no formato JSON\n",
        "        chat_id = message[\"message\"][\"chat\"][\"id\"]  # Extrai o ID do chat da mensagem\n",
        "\n",
        "        # Verifica se o ID do chat é o esperado\n",
        "        if chat_id == TELEGRAM_CHAT_ID:\n",
        "            # Cria um arquivo temporário para armazenar a mensagem\n",
        "            with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n",
        "                json.dump(message, fp)  # Escreve a mensagem JSON no arquivo\n",
        "\n",
        "            # Faz o upload do arquivo para o bucket S3\n",
        "            client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n",
        "\n",
        "    except Exception as exc:\n",
        "        # Se houver erro, loga o erro e retorna status 500\n",
        "        logging.error(msg=exc)\n",
        "        return {\n",
        "            'statusCode': 500,\n",
        "            'body': json.dumps({'error': str(exc)})\n",
        "        }\n",
        "\n",
        "    # Se tudo ocorrer bem, retorna status 200\n",
        "    return {\n",
        "        'statusCode': 200,\n",
        "        'body': json.dumps({'message': 'Mensagem processada com sucesso!'})\n",
        "    }\n"
      ],
      "metadata": {
        "id": "BlWcTuOUb-Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse modelo permite a ingestão automática e em tempo real das transações enviadas ao bot.\n",
        "\n",
        "- O AWS Lambda captura os dados do bot e armazena os arquivos brutos (JSON) no Amazon S3.\n",
        "\n",
        "**ETL (Extração, Transformação e Carga):**\n",
        "\n",
        "- Um segundo AWS Lambda processa os dados, limpando inconsistências e convertendo o formato JSON para Parquet.\n",
        "\n"
      ],
      "metadata": {
        "id": "m4ZH2q7WcQIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import boto3\n",
        "import os\n",
        "import pyarrow.parquet as pq\n",
        "import pyarrow as pa\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "s3 = boto3.client(\"s3\")\n",
        "\n",
        "RAW_BUCKET = os.environ[\"RAW_BUCKET\"]\n",
        "ENRICHED_BUCKET = os.environ[\"ENRICHED_BUCKET\"]\n",
        "\n",
        "# Expressão regular corrigida para capturar o valor decimal corretamente\n",
        "message_pattern = re.compile(r\"^\\s*(.*?),\\s*(\\d+(?:\\.\\d{1,2})?)\\s*,\\s*(\\d{2}/\\d{2}/\\d{4})\\s*,\\s*(.*?)\\s*,\\s*(.*?)\\s*,\\s*(.*?)\\s*$\")\n",
        "\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    try:\n",
        "        yesterday = (datetime.utcnow() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "        print(f\"Looking for files with date: {yesterday}\")\n",
        "\n",
        "        response = s3.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f\"telegram/context_date={yesterday}/\")\n",
        "\n",
        "        if \"Contents\" not in response:\n",
        "            return {\"statusCode\": 404, \"body\": \"Nenhum arquivo encontrado\"}\n",
        "\n",
        "        data_list = []\n",
        "        for obj in response[\"Contents\"]:\n",
        "            file_obj = s3.get_object(Bucket=RAW_BUCKET, Key=obj[\"Key\"])\n",
        "            file_data = json.loads(file_obj[\"Body\"].read().decode(\"utf-8\"))\n",
        "\n",
        "            print(f\"file_data: {file_data}\")\n",
        "\n",
        "            if isinstance(file_data, dict) and \"message\" in file_data:\n",
        "                message = file_data[\"message\"]\n",
        "\n",
        "                # Tenta corrigir a codificação\n",
        "                try:\n",
        "                    message_text = message.get(\"text\", \"\").encode(\"latin1\").decode(\"utf-8\")\n",
        "                except UnicodeDecodeError:\n",
        "                    message_text = message.get(\"text\", \"\")  # Se falhar, usa o texto original\n",
        "\n",
        "                match = message_pattern.match(message_text)\n",
        "                if match:\n",
        "                    print(f\"Grupos extraídos: {match.groups()}\")\n",
        "\n",
        "                    if len(match.groups()) == 6:\n",
        "                        description, value, date, category, method, bank = match.groups()\n",
        "\n",
        "                        data_list.append({\n",
        "                            \"descricao\": description,\n",
        "                            \"valor\": float(value),\n",
        "                            \"data\": datetime.strptime(date, \"%d/%m/%Y\").date(),\n",
        "                            \"categoria\": category,\n",
        "                            \"metodo\": method,\n",
        "                            \"banco\": bank\n",
        "                        })\n",
        "                    else:\n",
        "                        print(f\"Erro na correspondência: {message_text} não tem 6 grupos.\")\n",
        "\n",
        "            else:\n",
        "                print(\"O formato de file_data não é o esperado.\")\n",
        "\n",
        "        if not data_list:\n",
        "            return {\"statusCode\": 404, \"body\": \"Nenhuma mensagem válida encontrada\"}\n",
        "\n",
        "        # Converte os dados para uma tabela PyArrow\n",
        "        table = pa.Table.from_pylist(data_list)\n",
        "\n",
        "        # Define o nome do arquivo de saída\n",
        "        output_file = f\"processed/{yesterday}.parquet\"\n",
        "\n",
        "        # Salva a tabela no formato Parquet no diretório temporário\n",
        "        pq.write_table(table, \"/tmp/temp.parquet\")\n",
        "\n",
        "        # Carrega o arquivo Parquet no S3\n",
        "        s3.upload_file(\"/tmp/temp.parquet\", ENRICHED_BUCKET, output_file)\n",
        "\n",
        "        return {\"statusCode\": 200, \"body\": \"Processamento concluído\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"statusCode\": 500, \"body\": str(e)}\n"
      ],
      "metadata": {
        "id": "shR-Og6ZeZK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Obs: para utilizar o pacote PyArrow foi necessário utilizar uma camada na função Lambda pois o pacote não está instalado no ambiente padrão do AWS Lambda*\n",
        "\n",
        "- Os dados enriquecidos são armazenados em outro bucket no S3.\n",
        "\n",
        "- Para garantir que os dados sejam processados de forma eficiente e automática, utilizamos o Amazon EventBridge, que utiliza uma regra diária para ler os arquivos salvos no S3 no dia anterior e aciona automaticamente a função Lambda de transformação de dados.\n",
        "\n",
        "- O uso do EventBridge permite um fluxo de dados mais dinâmico e resiliente, garantindo que os arquivos sejam processados assim que forem recebidos no bucket RAW.\n",
        "\n",
        "**Apresentação:**\n",
        "\n",
        "- Utilização do AWS Athena para consultas SQL diretamente sobre os dados processados.Para isso, utilizamos o sequinte códido SQL para obter a tabela:\n",
        "\n",
        "```sql\n",
        "CREATE EXTERNAL TABLE gastos (\n",
        "    descricao STRING,\n",
        "    valor DOUBLE,\n",
        "    data DATE,\n",
        "    categoria STRING,\n",
        "    metodo STRING,\n",
        "    banco STRING\n",
        ")\n",
        "STORED AS PARQUET\n",
        "LOCATION 's3://telegram-pipeline-davi-enriched/processed/'\n",
        "TBLPROPERTIES (\"parquet.compression\"=\"SNAPPY\");\n",
        "\n",
        "```\n",
        "- Criação de dashboard com o Tableau para visualização interativa e análise gráfica dos gastos a partir dos dados da tabela disponíveis no Athena.\n",
        "\n",
        "## **4. Análise Exploratória de Dados**\n",
        "\n",
        "### **4.1. Fonte: Analisando os Dados no Athena**\n",
        "\n",
        "#### **Verificando a Qualidade dos Dados**\n",
        "Valores ausentes em alguma coluna :\n",
        "```sql\n",
        "SELECT\n",
        "    COUNT(*) AS total_registros,\n",
        "    SUM(CASE WHEN descricao IS NULL THEN 1 ELSE 0 END) AS descricao_nula,\n",
        "    SUM(CASE WHEN valor IS NULL THEN 1 ELSE 0 END) AS valor_nulo,\n",
        "    SUM(CASE WHEN data IS NULL THEN 1 ELSE 0 END) AS data_nula,\n",
        "    SUM(CASE WHEN categoria IS NULL THEN 1 ELSE 0 END) AS categoria_nulo,\n",
        "    SUM(CASE WHEN metodo IS NULL THEN 1 ELSE 0 END) AS metodo_nulo,\n",
        "    SUM(CASE WHEN banco IS NULL THEN 1 ELSE 0 END) AS banco_nulo\n",
        "FROM gastos;\n",
        "```\n",
        "Resultado: sem valores nulos na tabela\n",
        "\n",
        "![Valores Nulos](https://github.com/davicarv/Pipeline_Telegram/blob/main/Valores%20nulos%20.png?raw=true)\n",
        "\n",
        "#### **Analisando os Gastos**\n",
        "- Gastos por categoria :\n",
        " ```sql\n",
        "  SELECT categoria, SUM(valor) AS total_gasto\n",
        "  FROM despesas\n",
        "  GROUP BY categoria\n",
        "  ORDER BY total_gasto DESC;\n",
        "  ```\n",
        "![Gastos por categoria](https://github.com/davicarv/Pipeline_Telegram/blob/main/gastos_por_categoria.png?raw=true)\n",
        "\n",
        "Assim podemos entender a prioridade dos gastos do usuário\n",
        "\n",
        "- Gastos por método de pagamento\n",
        "```sql\n",
        "SELECT método, SUM(valor) AS total_gasto\n",
        "FROM gastos\n",
        "GROUP BY método\n",
        "ORDER BY total_gasto DESC;\n",
        "```\n",
        "![Gastos por categoria](https://github.com/davicarv/Pipeline_Telegram/blob/main/gastos_por_metodo.png?raw=true)\n",
        "\n",
        "Podemos ver então a preferência do usuário por pagamentos via PIX, débito e débito automático. Além disso é possível a relevânca do Vale Alimentação e que não há um uso tão grande de cartões de crédito.\n",
        "\n",
        "- Gastos por mês\n",
        "```sql\n",
        "SELECT date_format(data, '%Y-%m') AS mes, SUM(valor) AS total_gasto\n",
        "FROM gastos\n",
        "GROUP BY mes\n",
        "ORDER BY mes ASC;\n",
        "```\n",
        "![Gastos por mÊs](https://github.com/davicarv/Pipeline_Telegram/blob/main/gastos_por_mes.png?raw=true)\n",
        "\n",
        "É possível ver que os gastos costumam seguir um valor padrão próximo a R$4200. Observamos também uma economia no mês de fevereiro e abril, e um gasto mais alto no mês de julho.  \n",
        "\n",
        "### **4.2. Visualizando os dados em um dashboard**\n",
        "\n",
        "- Criação de dashboards no Tableau para melhor compreensão dos gastos por categoria, método de pagamento e banco.\n",
        "\n",
        "[📊 Acesse meu dashboard no Tableau Public](https://public.tableau.com/views/Gastos2024_17410708497240/Painel3?:language=pt-BR&publish=yes&:sid=&:display_count=n&:origin=viz_share_link)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qaOAcU7UeZnr"
      }
    }
  ]
}