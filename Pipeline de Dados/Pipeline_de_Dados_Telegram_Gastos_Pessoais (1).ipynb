{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline de Dados Telegram - Gastos Pessoais**\n",
        "\n",
        "## **1.Motiva√ß√£o do Projeto**\n",
        "\n",
        "Vivemos em um mundo onde dados s√£o gerados a todo momento. Mas como transformar essas informa√ß√µes em insights valiosos?\n",
        "\n",
        "Imagine que voc√™ quer monitorar seus gastos automaticamente, sem precisar inserir manualmente cada transa√ß√£o em uma planilha.\n",
        "\n",
        "Foi com essa ideia que nasceu este projeto: um **pipeline de dados do Telegram**, onde um chatbot captura mensagens contendo despesas, armazena os dados, processa e os disponibiliza para an√°lise.\n",
        "\n",
        "## **2. Contexto**\n",
        "\n",
        "### **Chatbots e a Gera√ß√£o de Dados**\n",
        "\n",
        "Os chatbots est√£o cada vez mais presentes no nosso dia a dia, facilitando intera√ß√µes e automatizando tarefas. O Telegram, por exemplo, permite a cria√ß√£o de bots que capturam mensagens enviadas pelos usu√°rios e as disponibilizam via API.\n",
        "\n",
        "### **Dados Transacionais vs. Dados Anal√≠ticos**\n",
        "\n",
        "- **Dados transacionais**: Registram eventos individuais no dia a dia de uma empresa ou usu√°rio (como uma compra).\n",
        "- **Dados anal√≠ticos**: S√£o estruturados e processados para gerar insights e auxiliar na tomada de decis√µes.\n",
        "\n",
        "Nosso projeto parte de dados transacionais capturados no Telegram e os transforma em um conjunto de dados anal√≠ticos para an√°lise de gastos pessoais.\n",
        "\n",
        "## **3. Arquitetura do Sistema**\n",
        "\n",
        "![diagrama pipeline_.jpg](https://github.com/davicarv/Portfolio/blob/main/Pipeline%20de%20Dados/Diagrama%20Pipeline.drawio.png?raw=true)\n"
      ],
      "metadata": {
        "id": "otCOle13UlzB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **3.1. Sistema Transacional: Captura de Dados do Telegram**\n",
        "\n",
        "- Um bot no Telegram recebe mensagens estruturadas no formato:\n",
        "  ```\n",
        "  Descri√ß√£o, Valor, Data, Categoria, M√©todo de Pagamento, Banco\n",
        "  ```\n",
        "- Essas mensagens s√£o coletadas usando a API do Telegram.\n",
        "\n",
        "### **3.2. Pipeline Anal√≠tico: Ingest√£o, ETL e Apresenta√ß√£o**\n",
        "\n",
        "**Ingest√£o:**\n",
        "\n",
        "Para capturar as mensagens enviadas ao bot do Telegram em tempo real, utilizamos um Webhook com O AWS API Gateway:\n",
        "\n",
        "- O Telegram envia automaticamente as mensagens recebidas pelo bot para uma URL definida (Webhook).\n",
        "\n",
        "- O Amazon API Gateway √© respons√°vel por expor a URL do Webhook de forma segura e escal√°vel. Ele atua como um intermedi√°rio entre o Telegram e a AWS, permitindo o recebimento de mensagens em tempo real.\n",
        "- Quando o bot recebe uma nova mensagem, o Telegram envia automaticamente os dados para o Webhook configurado.\n",
        "- O API Gateway recebe essa solicita√ß√£o e a encaminha para uma fun√ß√£o AWS Lambda, que processa a requisi√ß√£o, extrai os dados da mensagem e os armazena no Amazon S3 no formato JSON. A fun√ß√£o Lambda √© a seguinte:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SOoxcC9bW9JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "import boto3\n",
        "\n",
        "def lambda_handler(event: dict, context: dict) -> dict:\n",
        "    '''\n",
        "    Recebe uma mensagem do Telegram via AWS API Gateway, verifica no\n",
        "    seu conte√∫do se foi produzida em um determinado grupo e a escreve,\n",
        "    em seu formato original JSON, em um bucket do AWS S3.\n",
        "    '''\n",
        "\n",
        "    # Vari√°veis de ambiente\n",
        "    BUCKET = os.environ['BUCKET_NAME']\n",
        "    TELEGRAM_CHAT_ID = int(os.environ['TELEGRAM_GROUP_ID'])\n",
        "\n",
        "    # Vari√°veis l√≥gicas (Data e hora)\n",
        "    tzinfo = timezone(offset=timedelta(hours=-3))  # Definindo o fuso hor√°rio\n",
        "    date = datetime.now(tzinfo).strftime('%Y-%m-%d')  # Data formatada\n",
        "    timestamp = datetime.now(tzinfo).strftime('%Y%m%d%H%M%S%f')  # Timestamp √∫nico\n",
        "\n",
        "    filename = f'{timestamp}.json'\n",
        "\n",
        "    # Cliente boto3 para S3\n",
        "    client = boto3.client('s3')\n",
        "\n",
        "    try:\n",
        "        # Carrega o corpo da requisi√ß√£o\n",
        "        message = json.loads(event[\"body\"])  # Carrega o conte√∫do do evento no formato JSON\n",
        "        chat_id = message[\"message\"][\"chat\"][\"id\"]  # Extrai o ID do chat da mensagem\n",
        "\n",
        "        # Verifica se o ID do chat √© o esperado\n",
        "        if chat_id == TELEGRAM_CHAT_ID:\n",
        "            # Cria um arquivo tempor√°rio para armazenar a mensagem\n",
        "            with open(f\"/tmp/{filename}\", mode='w', encoding='utf8') as fp:\n",
        "                json.dump(message, fp)  # Escreve a mensagem JSON no arquivo\n",
        "\n",
        "            # Faz o upload do arquivo para o bucket S3\n",
        "            client.upload_file(f'/tmp/{filename}', BUCKET, f'telegram/context_date={date}/{filename}')\n",
        "\n",
        "    except Exception as exc:\n",
        "        # Se houver erro, loga o erro e retorna status 500\n",
        "        logging.error(msg=exc)\n",
        "        return {\n",
        "            'statusCode': 500,\n",
        "            'body': json.dumps({'error': str(exc)})\n",
        "        }\n",
        "\n",
        "    # Se tudo ocorrer bem, retorna status 200\n",
        "    return {\n",
        "        'statusCode': 200,\n",
        "        'body': json.dumps({'message': 'Mensagem processada com sucesso!'})\n",
        "    }\n"
      ],
      "metadata": {
        "id": "BlWcTuOUb-Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse modelo permite a ingest√£o autom√°tica e em tempo real das transa√ß√µes enviadas ao bot.\n",
        "\n",
        "- O AWS Lambda captura os dados do bot e armazena os arquivos brutos (JSON) no Amazon S3.\n",
        "\n",
        "**ETL (Extra√ß√£o, Transforma√ß√£o e Carga):**\n",
        "\n",
        "- Um segundo AWS Lambda processa os dados, limpando inconsist√™ncias e convertendo o formato JSON para Parquet.\n",
        "\n"
      ],
      "metadata": {
        "id": "m4ZH2q7WcQIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import boto3\n",
        "import os\n",
        "import pyarrow.parquet as pq\n",
        "import pyarrow as pa\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "s3 = boto3.client(\"s3\")\n",
        "\n",
        "RAW_BUCKET = os.environ[\"RAW_BUCKET\"]\n",
        "ENRICHED_BUCKET = os.environ[\"ENRICHED_BUCKET\"]\n",
        "\n",
        "# Express√£o regular corrigida para capturar o valor decimal corretamente\n",
        "message_pattern = re.compile(r\"^\\s*(.*?),\\s*(\\d+(?:\\.\\d{1,2})?)\\s*,\\s*(\\d{2}/\\d{2}/\\d{4})\\s*,\\s*(.*?)\\s*,\\s*(.*?)\\s*,\\s*(.*?)\\s*$\")\n",
        "\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    try:\n",
        "        yesterday = (datetime.utcnow() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "        print(f\"Looking for files with date: {yesterday}\")\n",
        "\n",
        "        response = s3.list_objects_v2(Bucket=RAW_BUCKET, Prefix=f\"telegram/context_date={yesterday}/\")\n",
        "\n",
        "        if \"Contents\" not in response:\n",
        "            return {\"statusCode\": 404, \"body\": \"Nenhum arquivo encontrado\"}\n",
        "\n",
        "        data_list = []\n",
        "        for obj in response[\"Contents\"]:\n",
        "            file_obj = s3.get_object(Bucket=RAW_BUCKET, Key=obj[\"Key\"])\n",
        "            file_data = json.loads(file_obj[\"Body\"].read().decode(\"utf-8\"))\n",
        "\n",
        "            print(f\"file_data: {file_data}\")\n",
        "\n",
        "            if isinstance(file_data, dict) and \"message\" in file_data:\n",
        "                message = file_data[\"message\"]\n",
        "\n",
        "                # Tenta corrigir a codifica√ß√£o\n",
        "                try:\n",
        "                    message_text = message.get(\"text\", \"\").encode(\"latin1\").decode(\"utf-8\")\n",
        "                except UnicodeDecodeError:\n",
        "                    message_text = message.get(\"text\", \"\")  # Se falhar, usa o texto original\n",
        "\n",
        "                match = message_pattern.match(message_text)\n",
        "                if match:\n",
        "                    print(f\"Grupos extra√≠dos: {match.groups()}\")\n",
        "\n",
        "                    if len(match.groups()) == 6:\n",
        "                        description, value, date, category, method, bank = match.groups()\n",
        "\n",
        "                        data_list.append({\n",
        "                            \"descricao\": description,\n",
        "                            \"valor\": float(value),\n",
        "                            \"data\": datetime.strptime(date, \"%d/%m/%Y\").date(),\n",
        "                            \"categoria\": category,\n",
        "                            \"metodo\": method,\n",
        "                            \"banco\": bank\n",
        "                        })\n",
        "                    else:\n",
        "                        print(f\"Erro na correspond√™ncia: {message_text} n√£o tem 6 grupos.\")\n",
        "\n",
        "            else:\n",
        "                print(\"O formato de file_data n√£o √© o esperado.\")\n",
        "\n",
        "        if not data_list:\n",
        "            return {\"statusCode\": 404, \"body\": \"Nenhuma mensagem v√°lida encontrada\"}\n",
        "\n",
        "        # Converte os dados para uma tabela PyArrow\n",
        "        table = pa.Table.from_pylist(data_list)\n",
        "\n",
        "        # Define o nome do arquivo de sa√≠da\n",
        "        output_file = f\"processed/{yesterday}.parquet\"\n",
        "\n",
        "        # Salva a tabela no formato Parquet no diret√≥rio tempor√°rio\n",
        "        pq.write_table(table, \"/tmp/temp.parquet\")\n",
        "\n",
        "        # Carrega o arquivo Parquet no S3\n",
        "        s3.upload_file(\"/tmp/temp.parquet\", ENRICHED_BUCKET, output_file)\n",
        "\n",
        "        return {\"statusCode\": 200, \"body\": \"Processamento conclu√≠do\"}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"statusCode\": 500, \"body\": str(e)}\n"
      ],
      "metadata": {
        "id": "shR-Og6ZeZK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Obs: para utilizar o pacote PyArrow foi necess√°rio utilizar uma camada na fun√ß√£o Lambda pois o pacote n√£o est√° instalado no ambiente padr√£o do AWS Lambda*\n",
        "\n",
        "- Os dados enriquecidos s√£o armazenados em outro bucket no S3.\n",
        "\n",
        "- Para garantir que os dados sejam processados de forma eficiente e autom√°tica, utilizamos o Amazon EventBridge, que utiliza uma regra di√°ria para ler os arquivos salvos no S3 no dia anterior e aciona automaticamente a fun√ß√£o Lambda de transforma√ß√£o de dados.\n",
        "\n",
        "- O uso do EventBridge permite um fluxo de dados mais din√¢mico e resiliente, garantindo que os arquivos sejam processados assim que forem recebidos no bucket RAW.\n",
        "\n",
        "**Apresenta√ß√£o:**\n",
        "\n",
        "- Utiliza√ß√£o do AWS Athena para consultas SQL diretamente sobre os dados processados.Para isso, utilizamos o sequinte c√≥dido SQL para obter a tabela:\n",
        "\n",
        "```sql\n",
        "CREATE EXTERNAL TABLE gastos (\n",
        "    descricao STRING,\n",
        "    valor DOUBLE,\n",
        "    data DATE,\n",
        "    categoria STRING,\n",
        "    metodo STRING,\n",
        "    banco STRING\n",
        ")\n",
        "STORED AS PARQUET\n",
        "LOCATION 's3://telegram-pipeline-davi-enriched/processed/'\n",
        "TBLPROPERTIES (\"parquet.compression\"=\"SNAPPY\");\n",
        "\n",
        "```\n",
        "- Cria√ß√£o de dashboard com o Tableau para visualiza√ß√£o interativa e an√°lise gr√°fica dos gastos a partir dos dados da tabela dispon√≠veis no Athena.\n",
        "\n",
        "## **4. An√°lise Explorat√≥ria de Dados**\n",
        "\n",
        "### **4.1. Fonte: Analisando os Dados no Athena**\n",
        "\n",
        "#### **Verificando a Qualidade dos Dados**\n",
        "Valores ausentes em alguma coluna :\n",
        "```sql\n",
        "SELECT\n",
        "    COUNT(*) AS total_registros,\n",
        "    SUM(CASE WHEN descricao IS NULL THEN 1 ELSE 0 END) AS descricao_nula,\n",
        "    SUM(CASE WHEN valor IS NULL THEN 1 ELSE 0 END) AS valor_nulo,\n",
        "    SUM(CASE WHEN data IS NULL THEN 1 ELSE 0 END) AS data_nula,\n",
        "    SUM(CASE WHEN categoria IS NULL THEN 1 ELSE 0 END) AS categoria_nulo,\n",
        "    SUM(CASE WHEN metodo IS NULL THEN 1 ELSE 0 END) AS metodo_nulo,\n",
        "    SUM(CASE WHEN banco IS NULL THEN 1 ELSE 0 END) AS banco_nulo\n",
        "FROM gastos;\n",
        "```\n",
        "Resultado: sem valores nulos na tabela\n",
        "\n",
        "![Valores Nulos](https://github.com/davicarv/Pipeline_Telegram/blob/main/Valores%20nulos%20.png?raw=true)\n",
        "\n",
        "#### **Analisando os Gastos**\n",
        "- Gastos por categoria :\n",
        " ```sql\n",
        "  SELECT categoria, SUM(valor) AS total_gasto\n",
        "  FROM despesas\n",
        "  GROUP BY categoria\n",
        "  ORDER BY total_gasto DESC;\n",
        "  ```\n",
        "![Gastos por categoria](https://github.com/davicarv/Pipeline_Telegram/blob/main/gastos_por_categoria.png?raw=true)\n",
        "\n",
        "Assim podemos entender a prioridade dos gastos do usu√°rio\n",
        "\n",
        "- Gastos por m√©todo de pagamento\n",
        "```sql\n",
        "SELECT m√©todo, SUM(valor) AS total_gasto\n",
        "FROM gastos\n",
        "GROUP BY m√©todo\n",
        "ORDER BY total_gasto DESC;\n",
        "```\n",
        "![Gastos por categoria](https://github.com/davicarv/Pipeline_Telegram/blob/main/gastos_por_metodo.png?raw=true)\n",
        "\n",
        "Podemos ver ent√£o a prefer√™ncia do usu√°rio por pagamentos via PIX, d√©bito e d√©bito autom√°tico. Al√©m disso √© poss√≠vel a relev√¢nca do Vale Alimenta√ß√£o e que n√£o h√° um uso t√£o grande de cart√µes de cr√©dito.\n",
        "\n",
        "- Gastos por m√™s\n",
        "```sql\n",
        "SELECT date_format(data, '%Y-%m') AS mes, SUM(valor) AS total_gasto\n",
        "FROM gastos\n",
        "GROUP BY mes\n",
        "ORDER BY mes ASC;\n",
        "```\n",
        "![Gastos por m√äs](https://github.com/davicarv/Pipeline_Telegram/blob/main/gastos_por_mes.png?raw=true)\n",
        "\n",
        "√â poss√≠vel ver que os gastos costumam seguir um valor padr√£o pr√≥ximo a R$4200. Observamos tamb√©m uma economia no m√™s de fevereiro e abril, e um gasto mais alto no m√™s de julho.  \n",
        "\n",
        "### **4.2. Visualizando os dados em um dashboard**\n",
        "\n",
        "- Cria√ß√£o de dashboards no Tableau para melhor compreens√£o dos gastos por categoria, m√©todo de pagamento e banco.\n",
        "\n",
        "[üìä Acesse meu dashboard no Tableau Public](https://public.tableau.com/views/Gastos2024_17410708497240/Painel3?:language=pt-BR&publish=yes&:sid=&:display_count=n&:origin=viz_share_link)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qaOAcU7UeZnr"
      }
    }
  ]
}